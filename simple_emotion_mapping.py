import os
import json
import pandas as pd
from tqdm import tqdm
from sklearn.model_selection import train_test_split

# ê°„ë‹¨ ëª…í™•í•œ ë§¤í•‘ (E10~E69ë¥¼ 10ë‹¨ìœ„ë¡œ)
# ë¶„ë…¸: E10~E19 â†’ 0
# ìŠ¬í””: E20~E29 â†’ 1
# ë¶ˆì•ˆ: E30~E39 â†’ 2
# ìƒì²˜: E40~E49 â†’ 3
# ë‹¹í™©: E50~E59 â†’ 4
# ê¸°ì¨: E60~E69 â†’ 5

EMOTIONS = ['ë¶„ë…¸', 'ìŠ¬í””', 'ë¶ˆì•ˆ', 'ìƒì²˜', 'ë‹¹í™©', 'ê¸°ì¨']

def get_emotion_from_code(emotion_code):
    """
    ê°ì • ì½”ë“œë¥¼ 6ê°€ì§€ ê°ì •ìœ¼ë¡œ ë§¤í•‘
    E10~E19 â†’ 0 (ë¶„ë…¸)
    E20~E29 â†’ 1 (ìŠ¬í””)
    E30~E39 â†’ 2 (ë¶ˆì•ˆ)
    E40~E49 â†’ 3 (ìƒì²˜)
    E50~E59 â†’ 4 (ë‹¹í™©)
    E60~E69 â†’ 5 (ê¸°ì¨)
    """
    try:
        # E10 â†’ 10, E25 â†’ 25
        code_num = int(emotion_code[1:])
        
        if 10 <= code_num <= 19:
            return 0  # ë¶„ë…¸
        elif 20 <= code_num <= 29:
            return 1  # ìŠ¬í””
        elif 30 <= code_num <= 39:
            return 2  # ë¶ˆì•ˆ
        elif 40 <= code_num <= 49:
            return 3  # ìƒì²˜
        elif 50 <= code_num <= 59:
            return 4  # ë‹¹í™©
        elif 60 <= code_num <= 69:
            return 5  # ê¸°ì¨
    except:
        pass
    
    return None

def extract_text_emotion(item):
    """JSONì—ì„œ í…ìŠ¤íŠ¸ì™€ ê°ì • ì¶”ì¶œ"""
    try:
        emotion_code = item['profile']['emotion']['type']
        emotion = get_emotion_from_code(emotion_code)
        
        if emotion is None:
            return None, None
        
        talk = item.get('talk', {})
        content = talk.get('content', {})
        
        # Human Speech (HS01, HS02, ...) ì¶”ì¶œ
        text_parts = []
        for key in sorted(content.keys()):
            if key.startswith('HS'):
                text = content[key]
                if text and len(str(text).strip()) > 3:
                    text_parts.append(str(text).strip())
        
        if text_parts:
            full_text = ' '.join(text_parts)
            return full_text, emotion
    
    except:
        pass
    
    return None, None

def process_directory(directory):
    """ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  JSON íŒŒì¼ ì²˜ë¦¬"""
    data_list = []
    
    json_files = []
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.endswith('.json'):
                json_files.append(os.path.join(root, file))
    
    print(f"  JSON íŒŒì¼: {len(json_files)}ê°œ")
    
    for json_file in tqdm(json_files, desc="  ì²˜ë¦¬ ì¤‘"):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                items = data if isinstance(data, list) else [data]
                
                for item in items:
                    text, emotion = extract_text_emotion(item)
                    if text and emotion is not None:
                        data_list.append({
                            'text': text,
                            'emotion': emotion
                        })
        except:
            pass
    
    return data_list

def main():
    """ì „ì²´ ì „ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤"""
    print("=" * 60)
    print("AI Hub ê°ì„± ëŒ€í™” ë°ì´í„° ì „ì²˜ë¦¬")
    print("6ê°€ì§€ ê°ì • (ë¶„ë…¸, ìŠ¬í””, ë¶ˆì•ˆ, ìƒì²˜, ë‹¹í™©, ê¸°ì¨)")
    print("=" * 60)
    
    # Training ë°ì´í„°
    print("\n[1/2] Training ë°ì´í„° ì²˜ë¦¬")
    train_dir = 'data/raw/Training'
    train_data = process_directory(train_dir)
    print(f"  âœ“ ì¶”ì¶œ: {len(train_data)}ê°œ")
    
    # Validation ë°ì´í„°
    print("\n[2/2] Validation ë°ì´í„° ì²˜ë¦¬")
    val_dir = 'data/raw/Validation'
    val_data = process_directory(val_dir)
    print(f"  âœ“ ì¶”ì¶œ: {len(val_data)}ê°œ")
    
    # DataFrame ìƒì„±
    train_df = pd.DataFrame(train_data)
    val_df = pd.DataFrame(val_data)
    
    # ì¤‘ë³µ ì œê±°
    train_df = train_df.drop_duplicates(subset=['text'])
    val_df = val_df.drop_duplicates(subset=['text'])
    
    print(f"\nì¤‘ë³µ ì œê±° í›„:")
    print(f"  Training: {len(train_df):,}ê°œ")
    print(f"  Validation: {len(val_df):,}ê°œ")
    
    # ê°ì • ë¶„í¬
    print("\nğŸ“Š Training ë°ì´í„° ê°ì • ë¶„í¬:")
    for i, emotion in enumerate(EMOTIONS):
        count = len(train_df[train_df['emotion'] == i])
        percentage = (count / len(train_df) * 100) if len(train_df) > 0 else 0
        print(f"   {emotion:6s} (E{(i+1)*10}~E{(i+1)*10+9}): {count:7,}ê°œ ({percentage:5.1f}%)")
    
    # ìƒ˜í”Œ í™•ì¸
    print("\nğŸ“ ë°ì´í„° ìƒ˜í”Œ í™•ì¸ (ê° ê°ì •ë³„ 2ê°œì”©):")
    for i, emotion in enumerate(EMOTIONS):
        emotion_df = train_df[train_df['emotion'] == i]
        if len(emotion_df) > 0:
            print(f"\n{'='*60}")
            print(f"[{emotion}] E{(i+1)*10}~E{(i+1)*10+9} ë²”ìœ„ - ì´ {len(emotion_df):,}ê°œ")
            print('='*60)
            samples = emotion_df.sample(min(2, len(emotion_df)))
            for idx, (_, row) in enumerate(samples.iterrows(), 1):
                print(f"{idx}. {row['text'][:80]}...")
    
    # Test ì„¸íŠ¸ ë¶„ë¦¬
    val_df, test_df = train_test_split(
        val_df, 
        test_size=0.5, 
        random_state=42,
        stratify=val_df['emotion']
    )
    
    print(f"\n{'='*60}")
    print(f"âœ“ ìµœì¢… ë°ì´í„° í¬ê¸°:")
    print(f"   í•™ìŠµ:   {len(train_df):7,}ê°œ")
    print(f"   ê²€ì¦:   {len(val_df):7,}ê°œ")
    print(f"   í…ŒìŠ¤íŠ¸: {len(test_df):7,}ê°œ")
    print(f"   ì´í•©:   {len(train_df) + len(val_df) + len(test_df):7,}ê°œ")
    
    # ì €ì¥
    os.makedirs('data', exist_ok=True)
    train_df.to_csv('data/train.csv', index=False, encoding='utf-8-sig')
    val_df.to_csv('data/val.csv', index=False, encoding='utf-8-sig')
    test_df.to_csv('data/test.csv', index=False, encoding='utf-8-sig')
    
    print("\nâœ“ ì €ì¥ ì™„ë£Œ:")
    print("   - data/train.csv")
    print("   - data/val.csv")
    print("   - data/test.csv")
    
    print("\n" + "=" * 60)
    print("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
    print("ìœ„ ìƒ˜í”Œì„ í™•ì¸í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì„¸ìš”.")
    print("=" * 60)

if __name__ == "__main__":
    main()
